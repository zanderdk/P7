\section{Related Work}\label{sec:related_work}

Before we can draw inspiration from solutions to related problems, we must consider what our problem is. As with almost all problems, this problem can be perceived from multiple angles, and modeled by just as many.

The linking problem can be seen as a problem of deducing semantic or contextual relations. Solutions to this problem usually involves a degree of textual analysis in order to determine whether a piece of text refers to another subject. There are usually two parts to this problem, which are each given a different level of importance, depending on the solution. First we got a syntactical recognition of references to some subject. One approach is to find keywords or shingles using some n-gram technique and matching those to subjects, as seen in (cite wikify!). 

Secondly there is semantic dertimination, where possible syntactical disambiguation is combatted. A prime example here is to determine whether the syntatical reference to a tree, semantically refers to a data structure or a type of plant. One of many ways of approaching this problem is to train a classifier, as seen in (cite learning to link). Here they attempt to determine the semantical reference by training on metrics for commonness, relatedness and context quality. In short, commonness is the probability distribution of references, relatedness is a measure of similarity between the referer and the possible referenced subject, and context quality is a measure of whether a given term is usually linked. The example given in (cite learning to link) is the english grammatical article \enquote{The}, which is used often, but rarely links to the subject article.

Another way of viewing the linking problem is as missing structural connections in a dataset. With this approach, solutions attempt to analyse a structure in order to gain insight into possible patterns that influences linking. For Wikipedia the most relevant structure to consider is a graph structure with articles as vertices. There are different ways to model edges in the graph. Examples of this include (cite Using Server Logs) and (cite Human Navigation Traces) where the authors create their edges the navigation of wikipedia's visitors, based on the belief that an optimal linking structure can be deducted from user behavior. Of course anything that can be considered a relation between any two articles, can be the basis for a set of edges, as explored in (cite Prediction in Complex Networks).

Regardless of your approach you must consider your metric for a good link. We have already introduced Wikipedia guidelines on linking (cite wiki guidelines), which is Wikipedias own view of a good set of metrics. However, even though they clearly hold authority on the matter, there are alternatives that are at least worth considering. In (cite Using Server Logs) and (cite Human Navigation Traces) they consider good links to be ones who are in use, and as such they rank their results based on server logs.

\todo{mangler overgang til maskine laering}

%Linking by sematics & naive bayes http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.cikm07.pdf Wikify! Linking Documents to Encyclopedic Knowledge
%https://pdfs.semanticscholar.org/07ab/d02f02774d178f26ca99937e5f94001a9ec9.pdf Learning to Link with Wikipedia
%Hyperlink Structure Using Server Logs http://cs.stanford.edu/people/jure/pubs/hyperlinks-wsdm16.pdf
%Human Navigation Traces http://cs.stanford.edu/people/jure/pubs/wiki-www15.pdf
%Prediction in Complex Networks https://arxiv.org/PS_cache/arxiv/pdf/1010/1010.0725v1.pdf




%To find missing links, our idea is to mimic how the contributors on Wikipedia link articles together. In other words, we want to learn how to link articles together by looking at how links are currently inserted/not inserted. This is is essentially the idea of machine learning, which we will be the main part of our solution idea. The following sections will expand on this idea in-depth.




%Wikipedia is the subject of multiple papers and research projects~\cite{wiki-research-newsletter}.


%Because of the subjective guidelines, we need to mimic how the contributors link articles together by looking at how they are currently linked. This is essentially the idea of machine learning, which we will be the main part of our solution idea. This chapter will analyze this aspect.