\todo{needs to be reviewed so that it does not repeat too much from the previous introduction section}
The content of Wikipedia is produced and maintained via crowdsourcing. That means that a large number of users collaboratively add and review content. As described in the previous section, it is non-trivial to find the correct articles to link when editing a Wikipedia article. As the content size increases, the complexity of linking articles also increases, further burdening Wikipedia contributors. 

We will in this report investigate whether we can use computers to automate finding missing links on Wikipedia articles, in order to ease the burden on users. The linking problem, namely whether two articles should be linked, is not easy to define in an objective manner, as it is inherently subjective; there is no true answer to this problem. The focus on our approach will therefore be on article link suggestions, instead of definitive answers. This gives us the nice property that lower confident results can also be included in the results presented by our approach.

To find missing links, our idea is to mimic how the contributors on Wikipedia link articles together. In other words, we want to learn how to link articles together by looking at how links are currently inserted/not inserted. This is is essentially the idea of machine learning. 

Our solution idea to the problem of finding missing links is therefore machine learning. The following sections will expand on this idea in-depth.