\section{Database}\label{sec:db}
Our approach to identifying missing links requires readily available data, which we facilitate by storing the required data in a local database. This database is the first component in the main pipeline seen in \cref{fig:system-overview}. 

\subsection{Database Design}\label{sec:db_design}
Because of the need to store a graph as mentioned in \cref{sec:choice_of_graph}, a natural choice is to use a native graph database. We use Neo4j~\cite{neo4j} as it performs well for graph based queries, and supports extensions to its query language through Java plugins. The data model in Neo4j is based on nodes, relationships between nodes, and properties on these. Each node and relationship can be annotated with labels to distinguish between types when querying the database.

We store Wikipedia articles as nodes with their title as a property, and links between articles as relationships. Labels are used to distinguish between types of articles and links.

\begin{table}[tbp]
  \centering
    \begin{tabular}{@{}p{.21\textwidth}p{.46\textwidth}r@{}}
      \toprule
      \textbf{Label} & \textbf{Description} & \textbf{Count} \\
      \midrule
      \mono{Article} & A Wikipedia article & \num{11159213} \\
      \mono{FeaturedArticle} & A Wikipedia article marked as \emph{Featured} & \num{4820} \\
      \mono{GoodArticle} & A Wikipedia article marked as \emph{Good} & \num{23741}\\
      \mono{RedirectPage} & A redirecting Wikipedia page &\num{7013417} \\
      \midrule
      & Total number of nodes & \num{18172630} \\
      \bottomrule
    \end{tabular}
    \caption[Node labels in the database]{Node labels in the database. Note that some nodes have multiple labels.}%
    \label{tab:db_labels_nodes}
\end{table}
\begin{table}[tbp]
    \centering
    \begin{tabular}{@{}p{.21\textwidth}p{.46\textwidth}r@{}}
      \toprule
      \textbf{Label} & \textbf{Description} & \textbf{Count} \\
      \midrule
      \mono{LinksTo} & A link between two articles & \num{138422339} \\
      \mono{TrainingData} & A link that can be used during training & \num{294857} \\
      \mono{TestData} & A link that is used only during testing & \num{147429} \\
      \mono{RedirectsTo} & An edge describing a redirect & \num{7013417} \\
      \midrule
      & Total number of relationships & \num{145878042} \\
      \bottomrule
    \end{tabular}
    \caption[Relationship labels in the database]{Relationship labels in the database}%
    \label{tab:db_labels_edges}
\end{table}

\subsection{Populating the Database}\label{sec:db_populate}
%Because Wikipedia requests that bots are not used to crawl the articles~\cite{wiki-bots}, we instead use a readily available dataset from DBpedia~\cite{dbpedia}. This dataset is just a dump of all Wikipedia \emph{pages}. The pages consists of for example articles, user pages, and talk pages. Since we are only interested in articles, we prune non-article pages based on the namespace prefixes used on Wikipedia.
Because Wikipedia requests that bots are not used to crawl the articles~\cite{wiki-bots}, we instead use readily available datasets\footnote{Data extracted from Wikipedia dumps in October 2015} from DBpedia~\cite{dbpedia}. The datasets used are a list of all page links and a list of page redirects. The pages consists of articles as well as pages for users, talks, files, etc. Since we are only interested in articles, we prune non-article pages based on the namespace prefixes used on Wikipedia.

Redirects are responsible for redirecting synonyms and common misspellings to the main article. For example, trying to access the article on ``Santa'' will redirect to ``Santa Claus''. The redirects are necessary to include since they are referred to by many links. We do not handle these redirects when creating the database. Instead we handle them by following them as needed when we later traverse the graph.

%To add relationships between the article nodes in the the database, we could have parsed the text in each article and created edges based on all encountered links. However, DBPedia have created a separate dataset containing links in an accessible tuple format:
%\begin{center}
%\mono{\emph{<source\_page> <type> <target\_page>}}
%\end{center}

%We therefore use this dataset instead of manually extracting the links.
We create nodes for all article and redirect pages and relationships for the links and redirects, with the labels seen in \cref{tab:db_labels_nodes,tab:db_labels_edges}. While importing the articles and links into the database, additional labels \mono{FeaturedArticle} and \mono{GoodArticle} are also added to  \emph{featured} and \emph{good} articles respectively.

As seen in \cref{tab:db_labels_edges}, the links are split into three groups, \mono{LinksTo}, \mono{TrainingData}, and \mono{TestData}, to later accommodate test and evaluation of the classifier. The split is made randomly, according to a partitioning given in \cref{sec:classifier}.

%page_links_unredirected_en.ttl.bz2
%redirects.en.ttl.bz2
