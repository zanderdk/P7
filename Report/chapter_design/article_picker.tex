\section{Candidate Generator}
The candidate generator component is responsible for providing an ordering of article pairs that are to be classified. In this section, we motivate this component and describe our approach to generate candidate pairs.

The database contains roughly 11 million articles, which results in $1.21 \times 10^{14}$ article pairs, making a brute force approach that generates all article pair permutations infeasible. Considering that the highest number of links on an article\footnote{The article in question is \enquote{List of Places In Afghanistan}} is currently 7130, and that the brute force approach would check 11 million potential links per article, it is safe to assume that most of these article pairs should not be linked.

Therefore, a more efficient selection method is required, that seeks to order the article pairs, such that those which should be linked, will generally be evaluated in the pipeline before those that should not. The candidate generator attempts to solve this task of efficiently selecting pairs. A perfect ordering method would result in having all the article pairs that should be linked occur before any article pair that should not. While such a method is unrealistic, it can serve as an ideal example. We only require the method to be a heuristic that performs reasonably well, generating enough candidate pairs for providing a sufficient number of link suggestions. 

The problem here is that in order to evaluate the exact performance of a policy, we would need to know if the candidate pairs it suggests, will be classified mostly as positive. This requires classifying the whole data set, hereby defeating the whole purpose of the candidate generator.

%Because such an evaluation of the candidate generator would produce the results of the classifier, it would in turn make the method obsolete for the tested pairs, since they would now have been classified. 

%It is not possible to evaluate the exact performance of a heuristic. First of all, if we wanted to label

%If we wanted to evaluate the exact performance of a heuristic, we could only do so through a classifier, since this is the result that matters. A heuristic that performs well on its own, could perform bad in combination with a classifier. But even if we wanted to compare two heuristics on the same classifier, we would not be able to guarantee that the performance of the best heuristic would generalize beyond the training data.

%Evaluating the heurisic is not worthwile, as the only sensible way to evaluate the policy is to use the classifier on the generated article pairs.

%One metric to evaluate the performance of a chosen heuristic is to count the number of link suggestions per 1000 pairs. However in order to determine this score, the classification step has to be run on the data set. Doing this, however, defeats the whole purpose of the candidate generator.

%In order to evaluate the performance of a chosen policy, the number of art a classifier has to be run on the proposed candidate pairs. This need obsoletes the policy, as 

%\todo{ikke den fede formulering. Lad dog vær med at bruge tid på dette før til aller sidst. Andre ting er vigtigere} 
Therefore, we choose our heuristic based on intuition and preliminary tests, and the result is a combination of two approaches. One is based on a \emph{clickstream} dataset and the other on an n-gram analysis.

\subsection{Clickstream Approach}\label{sec:candidate_clickstream}

The clickstream approach is inspired by related work that uses server logs to predict missing links~\cite{hyperlink-structure-using-logs}. We use clickstream~\cite{wiki-clickstream} data from Wikipedia server logs, and as such it is based on user behavior. A clickstream data source is a list of requests that Wikipedia received within a given timespan.\footnote{We use a data source collected from March 1 -- March 31, 2016} A request holds information about a referrer, a resource, a count of the occurrence of this request, and a request type. The request type can be \emph{link}, \emph{external}, or \emph{other}. For this approach, the type \emph{other} is the only relevant one. A request of type \emph{other} means that the referrer and resource were both Wikipedia articles, but the referrer does not link to the resource. One source of this type of requests could be searches~\cite{wiki-clickstream}.

The heuristic for this approach, is that some of these requests will indicate that a user, after reading one article, was prompted to read another article, and that they did not have the possibility of following a link. While there are plenty of cases where this does not constitute a missing link, chances are that some of the requests are examples of this. The approach iterates through the clickstream data, picking out requests of type \emph{other}, and ranking them by their number of occurrences.

Though preliminary results using this approach have been promising, it only produces 1.7 million candidate pairs.  Therefore, we choose to complement it with another approach to generate a bigger set of candidate pairs.

\subsection{n-gram Approach}

For the complementary approach we took inspiration from~\cite{milne2008learning}, where they employ textual analysis to find article pairs. The inspiration lies in their use of n-grams to find article pairs. For each article we create a set of shingles from an n-gram search. We then search through the titles of Wikipedia articles, for ones that are contained in at least one of the shingles. This gives us a large set of article pairs $(a,b)$, where article $a$ includes the title of article $b$.

However, this is a crude approach and a significant amount of the candidate pairs can be discarded. Consider the Wikipedia article on the word \enquote{the}. With the n-gram approach, nearly all encyclopedia articles would be in a candidate pair with this article, where only a fraction would be worth considering.

%A way to combat this would be to order the candidate pairs according to the inverse frequency of target articles. The intuition is that articles, which are rarely mentioned across all articles, will be more significant when they \emph{are} mentioned. It is likely that a frequency threshold will be required, since the advantages of the approach becomes negligible at some sufficiently high frequency.

Another considerable problem with the approach is that while it does provide many candidate pairs, it can not be guaranteed to order all possible pairs, and therefore it will not completely complement the clickstream approach. A preliminary test with a 5-gram search through featured articles produced more than a million candidate pairs. When all articles are searched, this approach will generate significantly more pairs than the clickstream approach. This will be sufficient for our current needs.

%from an article $a$ to an article $b$ in the time frame where the data was collected, as well as the method of navigation of these clicks. One of these methods of navigation is a \emph{teleportation}, which means the user ended up on article $b$ after having viewed article $a$, but not following a link.

%By selecting article pairs without an existing link and that users have navigated between by teleportation, the articles might be related and inserting a link between the articles might improve navigability.
