\section{Lessons Learned}
\todo{Title seems funny. On the other hand ``Lessons Learned'' is a completely valid term according to SWEBOK\@.}

In the making of this project, we have gained valuable experience in many areas such as project management, problem definition, working with large datasets, and feature learning in machine learning. This section will reflect on these core points.

\subsection{Narrowing the Problem}
In the beginning of a project period, we had to identify a problem to explore. We chose the broad subject of suggesting missing links on Wikipedia. A broad choice allows us to angle the solution construction in many possible directions. This gives the benefit of being able to adapt the solution to our interests and to quickly recover from a dead-end. A large amount of possible directions gives an opportunity to investigate and evaluate many approaches and options. However, this can be overwhelming since we will not always have the time to evaluate in a thorough manner.

Spending more time in the beginning of the project period on narrowing down the problem may have yielded a benefit. As such, we may have been able to iterate more rapidly on the solution. In retrospect we could also have worked on a subset of Wikipedia articles and only explored feature learning instead of also considering feature engineering. This would allow us to progress faster, but on the other hand would not expose us to the problems of feature engineering and handling large amounts of data. Ultimately one has to decide early on whether the project should be exploratory or focus on a narrow problem space.

\subsection{Large Data \& Prior Experience}
As mentioned above, we could have chosen to concern ourselves with a subset of Wikipedia. We chose not to. When working with big datasets, trying new approaches is hindered by the turnaround time of applying the new approach on the data. This means that we have to thoroughly consider the return of investment of every choice we make. In general, we have found machine learning to be largely a trial and error process. Experienced data scientists have a better intuition of the outcomes of certain approaches. We do not have such prior experience, and thus in order to gain experience we have to try things to get an intuition. To maximize the number of approaches we can try, we have to carefully plan ahead such that our computation resources are utilized most efficiently. Running parallel computation tasks has therefore been of major importance to the productivity of the group. We think we have gained a fairly good intuition of the machine learning aspect of the project, but we would have liked to have more time to try some of the new ideas that emerged late in the project. \todo{such as?}

\subsection{Data Preparation}
We found that we spent a significant portion of the project time on preparing data. At first, we did not know the direction the solution was taking, and we stored as much data as possible in the database. This was both slow and cumbersome. As we further narrowed the solution space, it became obvious what data was relevant to store. Preparing and finding a sensible data representation takes a certain amount of time that has to be considered when planning a machine learning project.

\subsection{Finding Features}
It is common knowledge in the field of machine learning that good features are vital. As mentioned above, we lack prior experience in machine learning. We originally started the project experimenting with manually engineered features. We roughly spent a month on this and the results were not encouraging. We found it difficult to reason about what constitutes a good feature. We therefore explored feature learning as a way for even inexperienced data scientists to find good features. An advantage of feature learning is the ability to automate large parts of the process. To find the best parameters for the feature learning algorithm, we performed parameter optimization. It was a good choice to do this, but in hindsight we could have been more careful about the process. We should plan what we want to optimize as our optimization function, in order to not waste time redoing parameter optimization work. Concretely, we could evaluate the parameters of the feature learning algorithms, not by testing the features on a classifier, but instead directly evaluate the features in some way. Introducing a classifier when finding parameters for the feature learner also introduces unneeded variables and also risk biasing the parameters towards the tested classifier.

\subsection{Data propagation}
Because of the pipeline architecture of the system, the accuracy of the output depends on all of the components.
Inaccuracies introduced into the system can propagate down the pipeline and greatly affect the results. As mentioned above some of these where due to ill-conceived choices made in the project.
Specifically, the accuracy of the classifier model depends on the accuracy of the feature model, both during training and in operation. Higher up in the pipeline the accuracy of the feature model depends on the quality and structure of the data, which subset was chosen for training, and how the hyperparameters are tuned. Furthermore the Candidate Generator component impacts which pairs that can be selected as link suggestions during system operation.
Being able to evaluate the components in isolation from each other would have been beneficial, but due to the nature of feature learning it can be difficult to reason about which configurations that ultimately will lead to good results.

%Points:
%- to minimize the problem, we could have narrowed the problem from the start, eg. a subset of wiki, choose a specific approach faster
%    - Would allow us to iterate faster
%    - Hard to generalize to the whole of wikipedia
%    - would narrow the solution space
%    - We could have had more focus on exploring approaches rather than implementing a final solution with a narrow approach set
%- dealing with large data needs special considerations
%    - takes time to try new things/approaches
%    - Scheduling/planning: Try to always keep a worker machine busy

\todo{mangler - There are many solutions to a problem - we only explore one solution}
%- It is hard to reason the effects of choices made before testing them. Experience in machine learning is a thing! Good that we have now had experience with it
%- Finding good features is vital
%- It can be hard to predict whether a solution will generalize before trying it
%- As machine learning is about experience, there is a lot of trial and error
%- Preparing data and finding the optimal data representation in eg. database takes time
%- feature learning: because we lack experience designing features, feature learning seems like an alternative that can yield good results even by inexperienced developers.
%    - Feature engineering is expensive
%- parameter optimization
%    - isolate components being optimized
%- plan ahead:
%    - for example in node2vec, we optimized towards f1, when precision would probably make more sense.
%    - define ahead what we want to optimize. Which use cases?